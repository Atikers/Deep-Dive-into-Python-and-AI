# Web Scraping and Data Exploration with the Diabetes Dataset
## 1) Scenario
In the quiet village of Tohono, in recent years, the community has faced a growing health crisis: a sharp increase in diabetes among its members, particularly the women. Dr. Pinch, a dedicated epidemiologist, has been working with the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK). She has been tasked with diagnosing and predicting diabetes within the community. With limited resources and the urgency of the situation, she turns to data science for a solution. Dr. Pinch decides to leverage the power of Python and data science to analyze a dataset containing medical records of the Pima women. This dataset includes various medical predictor variables such as the number of pregnancies, BMI, insulin levels, age, and more. The ultimate goal is to predict whether or not a patient has diabetes based on these diagnostic measurements.    

To achieve this, Dr. Pinch enlists the help of a aspiring data scientist, WonSeok Kim. Together, they aim to create a robust model that can accurately predict diabetes in the community, enabling early intervention and better healthcare planning.

In this project, **the Diabetes Dataset** is an online source and it is in CSV format.

**About Dataset**
 
**Context** : This dataset is originally from ***the National Institute of Diabetes and Digestive and Kidney Diseases***. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years of age of Pima Indian heritage.
 
**Content** : The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.
 
## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Setup
To start, I need to import the necessary library for data manipulation:
```python
Import pandas as pd      # For Importing pandas library
```
The dataset is available online in SCV format. We'll download it and load it into a DataFrame:
```python
filename = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/diabetes.csv"

async def download(url, filename):
    response = await pyfetch(url)
    if response.status == 200:
        with open(filename, "wb") as f:
            f.write(await response.bytes())

await download(filename, "diabetes.csv")
df = pd.read_csv("diabetes.csv")
```
After reading the dataset, I can use the `dataframe.head(n)` method to check the top n rows of the dataframe, where n is an integer.    
Contrary to `dataframe.head(n)`, `dataframe.tail(n)` will show me the bottom n rows of the dataframe.
```python
print("The first 5 rows of the dataframe")         # For Showing the first 5 rows using dataframe.head() method
df.head(5)
```
Then, I get the following :

![table1](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(1).jpg)

## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3) Steps : Exploring the Dataset
### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) Step 1 : Statistical Overview of Dataset
I can obtain a statistical summary and basic information about the dataset using the following methods :    
```python
df.info()        # For printing information about a DataFrame including the index dtype and columns, non-null values and memory usage.
df.describe()    # For providing basic statistical details like percentile, mean, standard deviation, etc.
```
Then, I get the following :

![table2](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(2).jpg)

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2) Step 2 : Identifying and Handling Missing Values
To identify missing values, I can use the `.isnull()`, `.notnull()` methods.
The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.    
so, the following codes will return a DataFrame indicating missing values with `True` for missing and `False` for present values.
```python
missing_data = df.isnull()
missing_data.head(5)
```
Then, I get the following :    

![table3](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(3).jpg)

"True" stands for missing value.    
"False" stands for not missing value.

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3) Step 3 : Counting missing values in each column
Using a for loop in Python, I can quickly figure out the number of missing values in each column.    
As mentioned above, "True" represents a missing value, "False" represents the value is present in the dataset.    
In the body of the for loop the method `.value_counts()` counts the number of "True" values.

```python
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")
```

### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4) Step 4 : Correcting data format
In Pandas, I will be using    
`.dtype()` to check the data type    
`.astype()` to change the data type    
Numerical variables should have type **float** or **int**
```python
df.dtypes
```


### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5) Step 5 : Visualization
**Visualization** is a powerful way to gain insights from dataset.    
I will use `Seaborn` and `Matplotlib` libraries for visualization(they are Python's most powerful visualization libraries).

```python
import matplotlib.pyplot as plt
import seaborn as sns
```
**Example : Pie Chart of Diabetic vs. Non-Diabetic Outcomes**
```python
labels='Not Diabetic','Diabetic'
plt.pie(df['Outcome'].value_counts(),labels=labels,autopct='%0.02f%%')
plt.legend()
plt.show()
```

Then, I get the following : 

![table4](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(4).jpg)

As I can see above, 65.10% females are not Diabetic and 34.90% are Diabetic.

## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4) Conclusion
In this project, I explored how to load and analyze a dataset using Python. I covered downloading the dataset, checking its structure, identifying and handling missing values, and visualizing data. These steps provide a solid foundation for further data analysis and machine learning tasks.
