# Web Scraping
## 1) Scenario
I will learn how to approach data acquisition in various ways and obtain necessary insights from a dataset.
I will successfully load the data into Jupyter Notebook and gain some fundamental insights via the Pandas Library.

In this case, **the Diabetes Dataset** is an online source and it is in CSV format.

> **About this Dataset**
> 
> **Context** : This dataset is originally from ***the National Institute of Diabetes and Digestive and Kidney Diseases***. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years of age of Pima Indian heritage.
> 
> **Content** : The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.
> 
## 2) Setup
```python
Import pandas as pd      # Import pandas library
```
```python
filename = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/diabetes.csv"

async def download(url, filename):
    response = await pyfetch(url)
    if response.status == 200:
        with open(filename, "wb") as f:
            f.write(await response.bytes())

await download(filename, "diabetes.csv")
df = pd.read_csv("diabetes.csv")
```
After reading the dataset, I can use the `dataframe.head(n)` method to check the top n rows of the dataframe, where n is an integer.    
Contrary to `dataframe.head(n)`, `dataframe.tail(n)` will show me the bottom n rows of the dataframe.
```python
print("The first 5 rows of the dataframe")         # show the first 5 rows using dataframe.head() method
df.head(5)
```
Then, I get the following :

![table1](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(1).jpg)

## 3) Steps
### (1) Step 1 : Statistical Overview of Dataset
```python
df.info()        # This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.
df.describe()    # This method is used to view some basic statistical details like percentile, mean, standard deviation, etc. of a data frame or a series of numeric values.
```
Then, I get the following :

![table2](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(2).jpg)

### (2) Step 2 : Identifying and Handling Missing Values
I will be using Python functions to identify these missing values. There are two methods to detect missing data:
`.isnull()`, `.notnull()`
The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.
```python
missing_data = df.isnull()
missing_data.head(5)
```
Then, I get the following :    

![table3](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(3).jpg)

"True" stands for missing value.    
"False" stands for not missing value.

### (3) Step 3 : Counting missing values in each column
Using a for loop in Python, I can quickly figure out the number of missing values in each column.    
As mentioned above, "True" represents a missing value, "False" represents the value is present in the dataset.    
In the body of the for loop the method `.value_counts()` counts the number of "True" values.

```python
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")
```

>Pregnancies    
>False    768    
>Name: Pregnancies, dtype: int64
>
>Glucose    
>False    768    
>Name: Glucose, dtype: int64    
>
>BloodPressure    
>False    768    
>Name: BloodPressure, dtype: int64    
>
>SkinThickness    
>False    768    
>Name: SkinThickness, dtype: int64    
>
>Insulin    
>False    768    
>Name: Insulin, dtype: int64    
>
>BMI    
>False    768    
>Name: BMI, dtype: int64    
>
>DiabetesPedigreeFunction    
>False    768    
>Name: DiabetesPedigreeFunction, dtype: int64    
>
>Age    
>False    768    
>Name: Age, dtype: int64    
>
>Outcome    
>False    768    
>Name: Outcome, dtype: int64

### (4) Step 4 : Correcting data format
In Pandas, I will be using    
`.dtype()` to check the data type    
`.astype()` to change the data type    
Numerical variables should have type **float** or **int**
```python
df.dtypes
```
  
>Pregnancies                    int64    
>Glucose                        int64    
>BloodPressure                  int64    
>SkinThickness                  int64    
>Insulin                        int64    
>BMI                            float64    
>DiabetesPedigreeFunction       float64    
>Age                            int64    
>Outcome                        int64    
>dtype: object    

### (5) Step 5 : Visualization
**Visualization** is one of the best way to get insights from the dataset.    
`Seaborn` and `Matplotlib` are Python's most powerful visualization libraries.  

```python
import matplotlib.pyplot as plt
import seaborn as sns
```
```python
labels='Not Diabetic','Diabetic'
plt.pie(df['Outcome'].value_counts(),labels=labels,autopct='%0.02f%%')
plt.legend()
plt.show()
```

Then, I get the following : 

![table4](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(4).jpg)

As I can see above, 65.10% females are not Diabetic and 34.90% are Diabetic.

