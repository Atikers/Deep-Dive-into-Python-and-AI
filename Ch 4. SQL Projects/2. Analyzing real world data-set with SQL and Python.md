# Analyzing real world data-set with SQL and Python 2

## 1) Scenario

After the previous analysis, The Council of Chicago has requested me to analyze many of their datasets. They have provided me with new datasets to analyze. I am very proud of the work I did with the previous datasets, and I am excited to work with the new datasets.

The datasets provided are:
1. **Socioeonomic Indicators in Chicago** : This dataset contains a selection of six socioeconomic indicators of public health significance and a “hardship index,” for each Chicago community area, for the years 2008 – 2012.
2. **Chicago Public Schools** : This dataset shows all school level performance data used to create CPS School Report Cards for the 2011-2012 school year.
3. **Chicago Crime Data** : This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present.

Let's dive into the data to uncover stories that can help shape the future of Chicago!

## 2) Steps

### Step 1: Store the datasets in database tables

Before I begin analyzing the data, I need to store it in a database, much like organizing files in a cabinet. I'll creat three tables in our database, one for each dataset. These tables will serve as my base for analysis.

The Three tables are:
1. **census_data**
2. **chicago_public_schools**
3. **chicago_crime_data**

#### Setting up the Environment

I'll use Python's `Pandas` and `sqlite3` libraries to load the datasets and create a SQLite database to store them. Here's how to set up your environment:
```python
import pandas as pd     # import pandas library for data manipulation
import sqlite3          # import sqlite3 library for database management
con = sqlite3.connect("FinalDB.db")    # Establish a connection to the SQLite database
cur = con.cursor()       # create a cursor object to interact with the database
```

#### Loading the SQL Magic Module

To simplify our SQL queries, I'll load the SQL magic module, which allows me to run SQL commands directly in a Jupyter Notebook:

```python
%load_ext sql   # load the SQL magic extension
%sql sqlite:///FinalDB.db   # connect to the SQLite database
```

#### Loading Data into Dataframes

Next, I'll use `pandas` to read the datasets from CSV files into dataframes: Load data from CSV files into dataframes:

```python
df1 = pd.read_csv("filepath.csv")
df2 = pd.read_csv("filepath.csv")
df3 = pd.read_csv("filepath.csv")
```

#### Loading the Dataframes into the database

Now that I have our data in dataframes, I'll load these dataframes into the database:

```python
df1.to_sql("census_data", con, if_exists='replace', index=False)
df2.to_sql("chicago_public_schools", con, if_exists='replace', index=False)
df3.to_sql("chicago_crime_data", con, if_exists='replace', index=False)
```

#### Re-Establishing connection

Finally, I ensure that our SQL magic module is still connected to the `FinalDB.db` database:

```python
%sql sqlite:///FinalDB.db
```

### Step 2: Data Analysis

With the datasets securely stored in our database, I'm ready to begin the analysis. Think of this as finally getting to examine the evidence I've meticulously collected and stored. Each SQL query will help me extract meaningful insights that can drive data-driven decisions. Let's get started!

### Find the Total Number of Crimes Recorded in the `chicago_crime_data` Table
To find the total number of crimes recorded in the `chicago_crime_data` table, I can use the `COUNT(*)` function in SQL. This function will count all the rows in the table, giving me the total number of crime records.

```python
%sql SELECT COUNT(*) AS total_crimes FROM chicago_crime_data;
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image.png)

### List Community Area Names and Numbers with Per Capita Income Less Than 11,000

To find the community areas where the per capita income is less than 11,000, I need to query the `census_data` table. Specifically, I will select the community area names and numbers where the per capita income is below the specified threshold.

```python
%sql SELECT community_area_name, community_area_number FROM census_data WHERE per_capita_income < 11000;
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-1.png)

### List All Case Numbers for Crimes Involving Minors

To find the case numbers for crimes involving minors, I need to query the `chicago_crime_data` table and filter for crimes that specifically involve minors. I will assume that there is a column in the dataset that indicates whether a crime involves a minor.

```python
%sql SELECT case_number FROM chicago_crime_data WHERE description LIKE '%MINOR%';
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-2.png)

### List All Kidnapping Crimes Involving a Child

To find all kidnapping crimes involving a child, I need to query the `chicago_crime_data` table and filter for records where the crime type is "Kidnapping" and involves a child. I will assume that there is a specific keyword or phrase in the `description` or `primary_type` columns that indicates a kidnapping involving a child.

```python
%sql SELECT case_number, date, primary_type, description FROM chicago_crime_data WHERE primary_type = 'KIDNAPPING' AND description LIKE '%CHILD%';
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-3.png)

### List the Kinds of Crimes Recorded at Schools (Without Repetitions)

To find the kinds of crimes that were recorded at schools, I need to query the `chicago_crime_data` table and filter for incidents that occurred at a school. I'll then select the distinct types of crimes to avoid repetitions.

```python
%sql SELECT DISTINCT primary_type FROM chicago_crime_data WHERE location_description LIKE '%SCHOOL%';
```

Then, I get the following :
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-4.png)

### List the Type of Schools Along with the Average Safety Score for Each Type

To find the average safety score for each type of school, I need to query the `chicago_public_schools` table. I will group the data by school type and calculate the average safety score for each group.

```python
%sql SELECT "Elementary, Middle, or High School" AS school_type, AVG(safety_score) AS average_safety_score FROM chicago_public_schools GROUP BY "Elementary, Middle, or High School";
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-5.png)

### List 5 Community Areas with the Highest Percentage of Households Below the Poverty Line

To find the 5 community areas with the highest percentage of households below the poverty line, I need to query the `census_data` table and order the results by the percentage of households below the poverty line in descending order. I will then select the top 5 records.

```python
%sql SELECT community_area_name, percent_households_below_poverty FROM census_data ORDER BY percent_households_below_poverty DESC LIMIT 5;
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-6.png)

### Identify the Most Crime-Prone Community Area (Display Community Area Number Only)

To find the community area that is most crime-prone, I need to determine which community area has the highest number of recorded crimes. I will query the `chicago_crime_data` table, group the data by community area number, count the number of crimes in each area, and then select the area with the highest count.

```python
%sql SELECT community_area_number FROM chicago_crime_data GROUP BY community_area_number ORDER BY COUNT(*) DESC LIMIT 1;
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-7.png)

### Find the Name of the Community Area with the Highest Hardship Index Using a Sub-query

To find the name of the community area with the highest hardship index, I can use a sub-query. The sub-query will first identify the maximum hardship index, and then the main query will retrieve the community area name corresponding to that index.

```python
%sql SELECT community_area_name FROM census_data WHERE hardship_index = (SELECT MAX(hardship_index) FROM census_data);
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-8.png)

### Determine the Community Area Name with the Most Number of Crimes Using a Sub-query

To find the community area name with the most number of crimes, I can use a sub-query. The sub-query will first identify the community area number with the highest crime count, and then the main query will retrieve the corresponding community area name from the `census_data` table.

```python
%sql SELECT community_area_name FROM census_data WHERE community_area_number = (SELECT community_area_number FROM chicago_crime_data GROUP BY community_area_number ORDER BY COUNT(*) DESC LIMIT 1);
```

Then, I get the following :    
![image](https://github.com/Atikers/Images/blob/main/Ch%204.%20SQL%20Projects/project%20%23%202/image-9.png)

## 3) Conclusion
In this analysis, I explored various datasets provided by The Council of Chicago, including socioeconomic indicators, public school performance data, and crime reports. By storing these datasets in a SQLite database and using SQL queries to extract insights, I was able to uncover important information that can help inform decisions and policies for the city.

Through this analysis, I have demonstrated the power of SQL and Python in transforming raw data into actionable insights. The results of this analysis can be used by the City of Chicago to make data-driven decisions that improve the quality of life for its residents, particularly in the areas of public safety, education, and economic development.

As I continue to work with these datasets, further analysis could delve deeper into specific issues, such as trends over time, correlations between different factors, and predictive modeling to anticipate future challenges. This ongoing analysis will help ensure that the city's resources are used effectively to address the needs of its communities!
