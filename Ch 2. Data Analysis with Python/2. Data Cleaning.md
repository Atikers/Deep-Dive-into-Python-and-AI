# Data Cleaning

## 1. Pre-processing Data in Python

It is the process of converting or mapping data from the initial "raw" form into another format, to make it ready for further analysis. It is often called ***data wrangling***, ***data cleaning***. It's like a process of cleaning raw materials to make them ready for production.

## 2. Dealing with Missing values in Python

### 1) What is missing value?

Missing values occur when no data value is stored for a variable in an observation. Missing values are a common occurrence in data. They can be due to various reasons such as data entry errors, equipment failures, interruptions in the data collection process, etc.

They are represented as "?", "N/A", "0" or just a blank cell.

### 2) How to deal with missing values?

#### 1. *Check with the data collection source*
- Check if the person or group that collected the data can provide any information about missing values.

#### 2. *Drop the missing values*
* Drop the variable
* Drop the data entry: If you don't have a lot of observations with missing data, dropping the particular entry is the best.
* Syntax:  
    ```python
    dataframe.dropna()
    ```
    * `axis=0` : drops the entire row
    * `axis=1` : drops the entire column 
* Examples:  
    ```python
    df.dropna(subset=["price"], axis=0, inplace=True)` # inplace=True: just writes the result back into the dataframe
    ```
    ```python
    df.dropna(subset=["price"], axis=0)` # This doesn't change the original dataframe
    ```
    
#### 3. *Replace the missing values*
* Replace the missing values with other(actual) values. e.g. average, the most frequent value, etc.
* Syntax:  
    ```python
    dataframe.replace(missing_value, new_value)
    ```
* Example:
    ```python
    mean=df["normalized-losses"].mean() # Calculate the mean of the column
    ```
    and then,
    ```python
    df["normalized-losses"].replace(np.nan, mean) # Replace NaN with the mean value
    ```

#### 4. *Leave it as missing data*
* We don't need to do anything with the missing data. We can leave it as it is. ***Let it be~***.
    
## 3. Data Formatting in Python

Data is usually collected from different places and in different formats. It is important to standardize the data into a common format so that the data can be easily understood and analyzed. It is like standardizing the units of measurement in a data set. So, Bringing data into a common standard of expression allows users to make meaningful comparisons(or looking for ways to spot fraud) ***e.g. N.Y./Ny/NY/New York => NY***, ***mpg => L/100km***

* Applying calculations to an entire column
    * Example:  
        ```python
        df["city-mpg"]=235/df["city-mpg"] # Convert mpg to L/100km
        df.rename(columns={"city-mpg":"city-L/100km"}, inplace=True) # Rename the column
        ```
* Sometimes the wrong data type is assigned to a variable. e.g. `price` is assigned as a string, but it should be a float.
    * Example:  
        ```python
        df["price"]=df["price"].astype("int") # Convert the data type to int
        ```
        > **Data types in Pandas:**  
        > Objects : "A", "Hello" - String  
        > Int64 : 1, 2, 3 - Integer  
        > Float64 : 1.1, 2.2, 3.3 - Float  

## 4. Data Normalization in Python

* Normalization enables a fairer comparison between different features, making sure they have the same impact. It is very important for computational reasons. 
* For example, 
    | age | income |                    
    |----------|----------|
    |   20  |   100000  |     
    |   30  |   20000 |
    |   40  |   500000  |

    The above table shows the age and income of three people. The age is in the range of 20-40, while the income is in the range of 20,000-500,000. The income is much larger than the age. So, the income will have a larger impact on the result. **The nature of the data biases the linear regression model to weigh income more heavily than age.** To avoid this, we need to normalize the data. 

    Like the following:

    | age | income |
    |----------|----------|
    |   0.2  |   0.2  |
    |   0.3  |   0.04 |
    |   0.4  |   1.0  |

    The above table shows the normalized age and income of three people. The age and income are now in the range of 0-1. Now, both age and income have the same impact on the result.

* Methods of normalizing data
    1. *Simple Feature Scaling*
        * Divides each value by the maximum value for that feature.
        * This makes the new values between 0 and 1.
            ```python
            df["length"]=df["length"]/df["length"].max()
            ```
    2. *Min-Max*
        * Takes each value, subtracts it from the minimum value of that feature, and then divides by the range of that feautre
        * This makes the new values between 0 and 1.
            ```python
            df["length"]=(df["length"]-df["length"].min())/(df["length"].max()-df["length"].min())
            ```
    3. *Z-score*
        * For each value, subtract the mean of the feature and then divide by the standard deviation of the feature.
        * This make the new values hover around zero and typically range between -3 and 3(but can be higher or lower).
            ```python
            df["length"]=(df["length"]-df["length"].mean())/df["length"].std()
            ```

