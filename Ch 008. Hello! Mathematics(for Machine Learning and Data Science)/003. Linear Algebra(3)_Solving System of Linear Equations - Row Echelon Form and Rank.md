# ***Linear Algebra(3) - Solving System of Linear Equations - Row Echelon Form and Rank***

## **The Rank of a Matrix**

**Have you ever wondered if there’s a way to measure just how much “useful information” a matrix contains?** Think of a matrix as a kind of container—if it’s filled to the brim, it holds a lot of valuable data; if it’s barely filled, there’s not as much information inside. The concept that captures this idea is called the **rank** of a matrix. In linear algebra, the rank lets us see how many independent equations or directions are truly locked up in the matrix.

### **Seeing Rank in Action: An Image Compression Tale**

A compelling example of why rank matters appears in **image compression**. When you store an image on a computer, you can think of that image as a large grid of numbers (each number represents a pixel’s intensity). The bigger or more detailed the image, the higher the matrix’s rank tends to be because there are more independent “details.”

- If a matrix (image) has **rank 200**, you might need a lot of storage space to represent all those details.  
- But there are clever methods, such as **Singular Value Decomposition (SVD)**, that allow you to reduce the rank while keeping the image recognizable.  
- By lowering the rank to, say, 50, you store far fewer independent details—meaning the file size shrinks—yet the image can still look nearly as sharp as the original.

This process is like folding a huge piece of fabric into a compact shape without creating too many wrinkles (distortions). That’s the power of rank: it’s a measure of how “rich” or “dense” the information in a matrix is.

### **Rank as “Information Content”**

To build more intuition, imagine you have a system of statements about animals:

1. “The dog is black.”  
2. “The cat is orange.”

Each statement provides unique information, so together they have two independent pieces of information. Now compare that to:

1. “The dog is black.”  
2. “The dog is black.”

Here, the second statement is just repeating the first one, adding no new information. Even though there are two statements, there’s effectively **only one piece of information**. Lastly, if both statements gave no details about the animals’ colors, then you’d have zero information regarding color.

In linear algebra terms, each **independent** statement (or equation) contributes to the **rank**. So if your matrix corresponds to these statements, the rank reveals how many truly independent clues (equations) are present.

### **From Systems of Equations to Matrices**

Let’s translate the same idea to actual linear equations:

- If you have two separate lines in a 2D system ($a$ and $b$ as your variables), and those lines intersect in a single point, you know each line adds new information. The rank is then 2 (since you have two independent lines).

- If your two equations are identical, then effectively there is only **one** unique line. You can’t pinpoint a single intersection; you end up with infinitely many solutions along that line. This system’s rank is 1.

- If the equations provide no unique line at all (everything is too vague), you end up with every point in the plane working as a solution. That means zero independent equations—so the rank is 0.

Mathematically, we say:
- **Rank 2** (full rank): only one solution (the intersection point).
- **Rank 1**: infinitely many solutions along a line.
- **Rank 0**: infinitely many solutions covering the entire plane.

### **Rank and the Dimension of the Solution Space**

Another way to see the rank’s power is to connect it to the **solution space** of a matrix. Suppose you’re dealing with a 2×2 system. Then:

- If the system’s rank is 2, the solution space has dimension $0$ (just a single point, the origin, for the homogeneous system).  
- If the system’s rank is 1, the solution space has dimension $1$ (a line of solutions).  
- If the system’s rank is 0, the solution space has dimension $2$ (the entire plane).

Notice a handy relationship for a 2×2 matrix:  

$$
\text{rank} + \text{dimension of the solution space} = 2.
$$

In general, for an $m \times n$ matrix, the idea expands so that:  

$$
\text{rank} + \text{dimension of the solution space} = n,
$$
where $n$ is the number of variables.

### **Non-Singular vs. Singular**

A matrix is called **non-singular** (or invertible) if it has **full rank**, meaning the rank equals the number of rows (or columns, whichever is smaller). This is equivalent to saying the matrix’s system of equations is able to “pin down” a unique solution. 

- A 2×2 matrix is **non-singular** if $\text{rank} = 2$.  
- Otherwise, it’s **singular**, meaning there’s some redundancy or lack of information in the equations.

### **Quick Example: Two Matrices**

1. **Matrix A** yields a solution space of dimension $0$. By our earlier formula, it must have rank $2$. Consequently, it’s non-singular.  
2. **Matrix B** yields a solution space of dimension $1$. Again, using rank + dimension = 2, we get rank $1$. Hence, it’s singular.

### **Key Takeaways**

- The **rank** tells you how many independent rows (or columns) a matrix has, which translates to how many pieces of unique information its system of equations provides.
- **Full rank** means the system is maximally informative—no redundancy among its rows or columns.
- Image compression techniques like **SVD** exploit rank to reduce storage needs while preserving as much detail as possible.

When you think about the rank of a matrix, remember this: it’s all about **how many unique “directions” or “independent clues”** you have. Whether it’s describing pixels in an image, equations in a system, or statements about colorful animals, the rank determines how rich and detailed the story really is.

---

## **The Rank of a Matrix in General**

### **Extending the Concept to 3×3 Matrices**

Previously, with 2×2 matrices, we saw that **rank** is a way to measure how many independent pieces of information a system of equations contains. For 3×3 matrices, the story is quite similar but now we have three equations in three unknowns (let’s call them $a$, $b$, and $c$).

1. **System 1 (Rank 3)**  
   - **All equations are independent.**  
   - No equation can be created as a linear combination (like an average or a sum) of the other two.  
   - Because each of the three equations supplies *new* information, the system’s rank is 3. Equivalently, the matrix has rank 3.

2. **System 2 (Rank 2)**  
   - Three equations are present, but one is just a combination of the others (for instance, it might be the average of the first and the third).  
   - Effectively, only two of those equations give genuinely new constraints.  
   - Hence, the system’s rank is 2, and so is the rank of its matrix.

3. **System 3 (Rank 1)**  
   - The first equation is new, but the second might be just 2 times the first, and the third perhaps 3 times the first.  
   - That means you only get *one* truly independent equation overall.  
   - Therefore, the system’s rank is 1, and the matrix rank is 1.

4. **System 4 (Rank 0)**  
   - All three equations provide no real information about $a$, $b$, or $c$.  
   - It’s like having three statements that are always true but don’t constrain the variables.  
   - That means zero independent pieces of information, giving a rank of 0.

### A Simpler Way: Row Echelon Form

At first glance, checking if an equation is a linear combination of the others can seem tedious. **Row echelon form** (often called REF) offers a more straightforward procedure:

- By performing elementary row operations - **swapping rows, multiplying a row by a non-zero constant, or adding a multiple of one row to another**, you transform the matrix into a form where the number of non-zero rows directly tells you the rank.
- Each non-zero row in this form corresponds to a genuinely new piece of information that can’t be derived from the other rows.

This procedure will become clearer as we explore the definitions of **row echelon form** and **reduced row echelon form** in the sections ahead. For now, the key takeaway is that **the rank counts how many “truly new” equations** you get in a system or, equivalently, how many non-zero rows appear in the row echelon form of the matrix.

### ***Key Takeaways***

- For 3×3 systems, **rank** measures how many independent constraints you have on your three unknowns.
- **Rank 3** means all three equations introduce new information (no redundancy).
- **Rank 2** indicates one of the three equations is dependent on the others.
- **Rank 1** suggests that only a single equation offers genuinely new details.
- **Rank 0** means none of the equations impose meaningful constraints.
- Coming up next, we’ll see **row echelon form** as a powerful method to identify the rank without having to guess about whether one equation is a linear combination of the others.

---

## **Row Echelon Form**

**Have you ever tried solving a jigsaw puzzle by first grouping similar pieces together, making the final assembly much easier?** 
**Row echelon form** serves a similar purpose for matrices: it’s a systematic way to “tidy up” rows so that you can quickly see a matrix’s key properties, like whether it’s singular or non-singular, and what its rank is.

### **What Is Row Echelon Form?**

A matrix is said to be in **row echelon form** if:

1. Any rows of all zeros are at the bottom of the matrix.  
2. Each non-zero row starts with a leading (leftmost) non-zero entry that is further to the right than the leading entry of the row above it.  
3. You typically scale rows so that these leading entries become $1$ for clarity (though it’s not strictly required for a basic row echelon form).

Visually, the non-zero rows form a “staircase” of leading entries, moving diagonally to the right as you go down.

### **How to Get There: Row Operations**

We use three legal **row operations** to transform any matrix into its row echelon form:

1. **Swap two rows.** (Like rearranging jigsaw puzzle pieces that are out of place.)  
2. **Multiply a row by a non-zero constant.** (Rescaling a puzzle piece so it “fits” better.)  
3. **Add a multiple of one row to another.** (Combining information from two puzzle pieces to simplify the layout.)

**Example**: Suppose you have a $2\times 2$ matrix  

$$
\begin{pmatrix}
5 & 1 \\
4 & -3
\end{pmatrix}
$$

A quick sketch of the process might look like this:

1. **Scale each row** so its leftmost non-zero entry becomes $1$:  

$$
\begin{pmatrix}
5 & 1 \\
4 & -3
\end{pmatrix}
\quad \to \quad
\begin{pmatrix}
1 & 0.2 \\
1 & -0.75
\end{pmatrix}
$$

2. **Eliminate** the $1$ in the lower-left corner by subtracting the first row from the second:  

$$
\begin{pmatrix}
1 & 0.2 \\
1 & -0.75
\end{pmatrix}
\quad \to \quad
\begin{pmatrix}
1 & 0.2 \\
0 & -0.95
\end{pmatrix}
$$

3. **Scale** the second row again so its leading entry becomes $1$:  

$$
\begin{pmatrix}
1 & 0.2 \\
0 & -0.95
\end{pmatrix}
\quad \to \quad
\begin{pmatrix}
1 & 0.2 \\
0 & 1
\end{pmatrix}
$$

Now you have a **row echelon form**, with easy-to-read leading $1$s on the diagonal.

### **Singular vs. Non-Singular: Row Echelon Form Tells the Story**

- **Non-Singular Matrix**  
  If, after these row operations, you end up with a row echelon form that has no zero rows (and thus has a leading $1$ in every row for a square matrix), the matrix is **non-singular** (invertible).  

- **Singular Matrix**  
  If a row becomes all zeros before you can place a leading 1 in it, the matrix is **singular**. In that case, there aren’t enough independent “pieces of information” to fill all the rows.

For example, with the matrix  

$$
\begin{pmatrix}
5 & 1 \\
10 & 2
\end{pmatrix}
$$

you quickly see the second row is just $2\times$ the first row. After scaling, you’ll discover a bottom row of zeros, meaning you can’t form two independent leading entries. Hence, it’s singular.

### **Row Echelon Form and Rank**

Here’s a neat shortcut:
- **The rank of a matrix** is the number of **leading 1s** in its row echelon form.  
- Equivalently, it’s also the number of non-zero rows in the row echelon form.

For instance:
1. A full-rank $2\times2$ matrix has **2** leading 1s in row echelon form.  
2. If you find only **1** leading 1 before hitting an all-zero row, the rank is **1**.  
3. If everything is **0**, the rank is **0**.

### **Key Takeaways**

1. **Row echelon form** simplifies a matrix into a nearly “triangular” shape, making it much easier to solve systems of equations or identify rank.  
2. **Rank** = number of non-zero rows (or leading 1s) in the row echelon form.  
3. A matrix is **non-singular** (invertible) if and only if its row echelon form has as many leading 1s as there are rows (i.e., no zero rows).  
4. **Singularity** arises when at least one row effectively collapses to zeros, revealing a dependency among rows.

Once you learn row echelon form, you’ll see how it elegantly connects to solution spaces, inverse matrices, and beyond—just like grouping puzzle pieces in a neat, recognizable pattern for easy completion.

---

## **Row Echelon Form in General**

### **Stepping Up to Bigger Matrices**

When we dealt with $2\times2$ matrices, obtaining row echelon form was straightforward. But what if you have a system of equations in three or more variables? The same logic applies: by using **row operations**, you can transform any $m\times n$ matrix into a simpler, stair-like shape that immediately reveals whether the matrix is singular or not—and exactly what its rank is.

- **Staircase Pattern**: Each non-zero row starts (from the left) further to the right than the row above it.  
- **Zero Rows at the Bottom**: Any rows consisting entirely of zeros appear below the non-zero rows.

### **A Quick Example**

Suppose we have a $3\times3$ system of equations involving variables $a, b,$ and $c$. When you solve the system by reducing step by step, you might notice a pattern:

1. **First Row**: All three variables $a, b, c$ appear.  
2. **Second Row**: One variable (say $a$) might be eliminated, leaving a new constraint in terms of $b$ and $c$.  
3. **Third Row**: Possibly only $c$ remains.

That’s exactly mirrored in the **row echelon form** of the corresponding matrix. You’ll see a diagonal of leading entries (called **pivots**) stepping down to the right, with zeros below each pivot.

### **What Do the “Stars” Mean?**

You’ll often see row echelon form described like this:  

$$\begin{pmatrix}* & * & * & \cdots & * \\
0 & * & * & \cdots & * \\
0 & 0 & * & \cdots & * \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & *
\end{pmatrix}
$$

- Each $*$ can be any real number (zero or non-zero).  
- Every row has a **pivot**—its leftmost non-zero entry—moved further right than the pivot in the row above.  
- Rows of all zeros, if any, sit at the bottom.

### **Counting Pivots = Rank**

A powerful takeaway is:
- The **rank** of a matrix equals the **number of pivots** in its row echelon form.  
- In some textbooks, you’ll see a version called the “**reduced** row echelon form,” where each pivot is turned into $1$ by dividing the entire row by that pivot. However, whether the pivot is $1$ or any other non-zero number doesn’t change the rank; it’s simply a stylistic choice that can make reading off solutions easier.

For example, if you end up with three non-zero pivots in a $3\times3$ matrix, the matrix has rank $3$. If only two pivots survive before you get a zero row, the matrix has rank $2$, and so on.

### **Singular vs. Non-Singular (Again)**

- **Non-Singular** (Invertible)  
  A square matrix is non-singular if it has a pivot in every row (and every column, for a square matrix). In other words, there are no zero rows once you reach the row echelon form.  
- **Singular**  
  If at least one row collapses to all zeros (indicating a dependency among the rows), the matrix is singular.

### **A Practical Note: Pivots as 1 vs. Other Values**

You might see two slightly different row echelon forms for the same matrix:

1. **Pivot Not Necessarily 1**: You stop once you’ve formed the staircase of non-zero entries.  
2. **Pivot = 1**: You go one step further by dividing each pivot row so that each pivot is 1.

Mathematically, both forms contain the same information. Converting the pivot to 1 just simplifies reading off solutions to a system of equations.

### **Key Takeaways**

- **Row echelon form** puts a matrix into a clean, staircase-like arrangement of pivots.  
- **Rank** is the count of those pivots (non-zero leading entries).  
- **Singular vs. Non-Singular**: If a square matrix has as many pivots as its dimension, it’s non-singular; otherwise, it’s singular.  
- **Pivot Normalization**: Changing a pivot from, say, 3 to 1 is purely a convenience and does not affect the rank.

Once you recognize this form, solving equations, finding ranks, and checking invertibility become as simple as counting the “stairs” in the matrix!

---

## **The Reduced Row Echelon Form**

## **The Gaussian Elimination Algorithm**
