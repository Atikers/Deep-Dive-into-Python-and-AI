# Project Overview
## 1) Scenario
For this project, I will assume the role of a Data Scientist / Data Analyst working for a new startup investment firm that helps customers invest their money in stocks.  
My job is to extract financial data like historical share price and quarterly revenue reportings from various sources using Python libraries and webscraping on popular stocks.  
After collecting this data I will visualize it in a dashboard to identify patterns or trends. The stocks I will work with are ***Tesla, Amazon, Nvidia***  

**Dashboard Analytics Displayed**

A dashboard often provides a view of key performance indicators in a clear way.  
Analyzing a data set and extracting key performance indicators will be practiced.  
Prompts will be used to support learning in accessing and displaying data in dashboards.  
Learning how to display key performance indicators on a dashboard will be included in this project.  
I will be using Plotly in this project for data visualization.  

**About Stock Shares**

A company's stock share is a piece of the company; more precisely:    

A stock (=equity) is a security that represents the ownership of a fraction of a corporation.    
This entitles the owner of the stock to a proportion of the corporation's assets and profits equal to how much stock they own. 
Units of stock are called **shares.**

An investor can buy a stock and sell it later. 
If the stock price increases, the investor profits, If it decreases, the investor with incur a loss. 
Determining the stock price is complex; it depends on the number of outstanding shares, the size of the company's future profits, and much more. 
People trade stocks throughout the day. The **stock ticker** is a report of the price of a certain stock, updated continuously throughout the trading session by the various stock market exchanges. 
In this lab, I will use the `y-finance API` to obtain the stock ticker and extract information about the stock. 







```python
Import pandas as pd      # Import pandas library
```
```python
filename = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/diabetes.csv"

async def download(url, filename):
    response = await pyfetch(url)
    if response.status == 200:
        with open(filename, "wb") as f:
            f.write(await response.bytes())

await download(filename, "diabetes.csv")
df = pd.read_csv("diabetes.csv")
```
After reading the dataset, I can use the `dataframe.head(n)` method to check the top n rows of the dataframe, where n is an integer.    
Contrary to `dataframe.head(n)`, `dataframe.tail(n)` will show me the bottom n rows of the dataframe.
```python
print("The first 5 rows of the dataframe")         # show the first 5 rows using dataframe.head() method
df.head(5)
```
Then, I get the table below :

![table1](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(1).jpg)

## 3) Steps
### (1) Step 1 : Statistical Overview of Dataset
```python
df.info()        # This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.
df.describe()    # This method is used to view some basic statistical details like percentile, mean, standard deviation, etc. of a data frame or a series of numeric values.
```
Then, I get the table below :

![table2](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(2).jpg)

### (2) Step 2 : Identifying and Handling Missing Values
I will be using Python functions to identify these missing values. There are two methods to detect missing data:
`.isnull()`, `.notnull()`
The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.
```python
missing_data = df.isnull()
missing_data.head(5)
```
Then, I get the table below :    

![table3](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(3).jpg)

"True" stands for missing value.    
"False" stands for not missing value.

### (3) Step 3 : Counting missing values in each column
Using a for loop in Python, I can quickly figure out the number of missing values in each column.    
As mentioned above, "True" represents a missing value, "False" represents the value is present in the dataset.    
In the body of the for loop the method `.value_counts()` counts the number of "True" values.

```python
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")
```

>Pregnancies    
>False    768    
>Name: Pregnancies, dtype: int64
>
>Glucose    
>False    768    
>Name: Glucose, dtype: int64    
>
>BloodPressure    
>False    768    
>Name: BloodPressure, dtype: int64    
>
>SkinThickness    
>False    768    
>Name: SkinThickness, dtype: int64    
>
>Insulin    
>False    768    
>Name: Insulin, dtype: int64    
>
>BMI    
>False    768    
>Name: BMI, dtype: int64    
>
>DiabetesPedigreeFunction    
>False    768    
>Name: DiabetesPedigreeFunction, dtype: int64    
>
>Age    
>False    768    
>Name: Age, dtype: int64    
>
>Outcome    
>False    768    
>Name: Outcome, dtype: int64

### (4) Step 4 : Correcting data format
In Pandas, I will be using    
`.dtype()` to check the data type    
`.astype()` to change the data type    
Numerical variables should have type **float** or **int**
```python
df.dtypes
```
  
>Pregnancies                    int64    
>Glucose                        int64    
>BloodPressure                  int64    
>SkinThickness                  int64    
>Insulin                        int64    
>BMI                            float64    
>DiabetesPedigreeFunction       float64    
>Age                            int64    
>Outcome                        int64    
>dtype: object    

### (5) Step 5 : Visualization
**Visualization** is one of the best way to get insights from the dataset.    
`Seaborn` and `Matplotlib` are Python's most powerful visualization libraries.  

```python
import matplotlib.pyplot as plt
import seaborn as sns
```
```python
labels='Not Diabetic','Diabetic'
plt.pie(df['Outcome'].value_counts(),labels=labels,autopct='%0.02f%%')
plt.legend()
plt.show()
```

Then, I get the below : 

![table4](https://github.com/Atikers/Images/blob/main/Project%20%232%20-%20image(4).jpg)

As I can see above, 65.10% females are not Diabetic and 34.90% are Diabetic.

