# ***Beyond Supervised Learning (2) - Anomaly Detection***

## ***Finding Unusual Events***

### ***Have you ever wondered how systems automatically catch “strange” or “rare” or "Fraudulent" behaviors?***

Meet **anomaly detection**, our second unsupervised learning algorithm. It learns what “normal” looks like from unlabeled data—so when something **unusual** shows up, it can raise a red flag. Whether it’s monitoring aircraft engines or spotting credit card fraud, anomaly detection is a **powerful tool** for safeguarding against unexpected or dangerous events.

---

### ***1. What Is Anomaly Detection?***

**Anomaly detection** looks at a dataset of **mostly “normal”** examples and tries to figure out **when a new example doesn’t fit** the usual pattern. It doesn’t need labels for “bad” or “good”; it just knows what **typical** behavior looks like.

- **Analogy**: Imagine you watch a flock of birds daily. You learn to recognize how they usually move and sound. If a bird suddenly **flies very differently** or makes an **odd** sound, your instinct says something’s off—maybe it’s injured or a different species. That’s the essence of anomaly detection: **spotting the odd one out**.

---

### ***2. Key Idea: Probability Modeling***

A common way to do anomaly detection is by modeling a **probability distribution** $p(x)$ over your data’s features. For each data point:
1. **Estimate** how likely (probable) that point is, based on past “normal” data.
2. If a **new** point $x_{\text{test}}$ has a **very low** probability (below some small $\epsilon$), it’s flagged as an **anomaly**.

```text
if   p(x_test) < ε  →  "Unusual/Anomaly"  
else                →  "Looks Normal"
```

- **Example**  
  - For an aircraft engine, features could be $x_1$ = heat generated, $x_2$ = vibration intensity, etc.  
  - We look at **all** the normal engines we have and learn a model $p(x)$ of how an engine typically behaves.  
  - When a **new** engine arrives, we measure ($x_1, x_2$). If $p(x_{\text{test}})$ is extremely small, the engine might be flawed or **risky**, so we **inspect** it further.

---

### ***3. Where It’s Used***

1. **Manufacturing**  
   - Aircraft engines, circuit boards, smartphones… you want to catch **defective** products before shipping them to customers.
   - By learning what “normal” products look like, anomaly detection can help **flag** suspicious items for **extra** testing.

2. **Fraud Detection**  
   - Monitor user activity (e.g., login frequency, transaction counts, typing speed).  
   - If a user’s behavior is **unusually** high or low compared to the general population, it might indicate **fraud**—warranting an extra check.

3. **System Monitoring**  
   - Track server or computer health (CPU usage, memory usage, network traffic).  
   - If one machine’s behavior **deviates** far from the “norm,” you might have a **hardware failure** or **security breach**.

> **Note**: Typically, we **don’t** immediately label a flagged item as 100% fraudulent or broken; we **investigate further** to confirm whether it’s really an issue or just an unusual but harmless event.

---

### ***4. Why It Works***

- **Most data is normal**  
  You have plenty of examples showing how a “good” engine or a “legitimate” user usually behaves.
- **Learn what’s typical**  
  Model $p(x)$ so it’s **large** in the dense “normal” region and **small** on the fringes.
- **Detect the rare**  
  If a new point falls **way outside** the normal region, $p(x_{\text{test}})$ becomes **tiny**, and we can **sound the alarm**.

---

### ***5. Key Takeaways***

1. **Unsupervised Approach**  
   - No labeled “bad” examples needed. We rely on the assumption that **most** data is normal.

2. **Probability Threshold**  
   - If $p(x_{\text{test}}) < \epsilon$, mark it as **anomaly**. Choosing $\epsilon$ carefully balances missing real anomalies vs. raising too many false alarms.

3. **Broad Applications**  
   - From **fraud** and **manufacturing** to **network** and **system monitoring**, anomaly detection **keeps watch** for out-of-the-ordinary events.

4. **Next Steps**  
   - Often, we use **Gaussian distributions** (or other advanced density estimations) to model $p(x)$.  
   - After flagging anomalies, **human** or **automated** checks can confirm if the item is truly problematic.

Anomaly detection may not be as talked about as other AI techniques, but it’s a **silent hero** in many industries. By learning what “normal” looks like, it shines a spotlight on potential **failures, frauds, or faults**, protecting everything from airplane engines to entire data centers. And you can apply it to **your own life** to become more **aware** of unusual patterns or success. That's the true power of anomaly detection. Let's dive in and see how it works!

---

## ***Gaussian (Normal) Distribution***

### ***Have you ever wondered why so many things in nature follow a “bell-shaped” curve?***

In many real-world situations—like measuring people’s heights or looking at how temperatures vary—data often clusters around a **center** value and then gently tapers off on either side. This shape is called the **Gaussian** (or **Normal**) distribution. It’s also known as a **bell curve** because, well…it looks like a bell!

---

### ***1. What is the Gaussian Distribution?***

Suppose you have a single feature $x$—for example, the height of a person. If $x$ follows a **Gaussian distribution** with:
- Mean (average) $\mu$  
- Variance $\sigma^2$ (where $\sigma$ is called the **standard deviation**)

then the **probability** that $x$ takes a particular value is given by:

$$
p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x - \mu)^2}{2\sigma^2}}
$$

- **$\mu$ (mu)** is where the **peak** of the bell is (the center).
- **$\sigma$ (sigma)** is how “spread out” the bell is. A **large** $\sigma$ means a wider curve, while a **small** $\sigma$ means a narrower, taller curve.

> **Analogy**: Think of **$\mu$** like the **average** height in your class. If most people cluster around that height, you’ll see a **peak** near $\mu$. The **standard deviation** $\sigma$ tells you how **much** people’s heights vary from that average. If $\sigma$ is large, some people are **much taller** or **much shorter** than $\mu$.

---

### ***2. Visualizing the Bell Curve***

If you plotted many measurements of $x$—like drawing a **histogram** of a thousand heights—you might get a shape that **resembles** the smooth Gaussian curve. The more data you have, and the more it truly follows a “centered + spread” pattern, the more it looks like that **bell**.

- **Center at $\mu$**: That’s the highest point of the curve.
- **Spread of $\sigma$**: How wide or narrow the bell appears.

| **Parameter** | **Effect**          |
|---------------|---------------------|
| $\mu$ (mean)  | Shifts the bell left or right.  |
| $\sigma$ (standard deviation)      | Stretches or compresses the bell’s width. |

---

### 3. Changing $\mu$ and $\sigma$: Examples

1. **$\mu = 0, \sigma = 1$**  
   - Centered at 0, with a moderate spread.
2. **$\mu = 0, \sigma = 0.5$**  
   - Still centered at 0, but more **narrow** and **tall**.
3. **$\mu = 0, \sigma = 2$**  
   - Still centered at 0, but very **wide** and **short**.
4. **$\mu = 3, \sigma = 0.5$**  
   - Shifted to **3** on the x-axis, narrower spread.

The **area under** each curve is **1**, which is how probabilities stay consistent (the total probability must be 1).

---

### 4. Estimating $\mu$ and $\sigma^2$ from Data

When you have a dataset $\{x^{(1)}, x^{(2)}, \dots, x^{(m)}\}$ of $m$ points, you can **estimate** the Gaussian parameters like this:

$$
\mu = \frac{1}{m} \sum_{i=1}^{m} x^{(i)},
$$

$$
\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} \bigl(x^{(i)} - \mu\bigr)^2.
$$

- $\mu$ is just the **average** of all your data points.
- $\sigma^2$ is the **average** of the squared differences from that mean (i.e., how “spread out” the data is).

> **Fun Fact**: In statistics, some formulas use $1/(m-1)$ instead of $1/m$ for $\sigma^2$(If you want to know more, search for "Unbiased Estimator", "Degrees of Freedom", "Bessel's Correction"), but for many practical cases, $1/m$ is perfectly fine.

---

### ***5. Gaussian Distribution for Anomaly Detection***

Once you’ve **modeled** your data as a Gaussian, you get a **probability** for each new value of $x$:
- If $p(x)$ is **high**, $x$ seems “normal” (close to the center).
- If $p(x)$ is **low**, $x$ might be “anomalous” (far from the center), suggesting a **possible anomaly**.

This idea **extends** easily to more features (e.g., 2, 3, or 100 features) in higher-dimensional versions of the Gaussian. But the core concept remains:  
**Model** your normal data with a “bell” shape, then **flag** anything that’s unusually far from that bell as a potential anomaly.

---

### ***6. Key Takeaways***

1. **A Bell-Shaped World**  
   Many **natural** or **human** measurements (height, test scores, etc.) approximately follow this “bell” pattern.

2. **Parameters ($\mu$, $\sigma$) Define the Curve**  
   - $\mu$ says **where** it’s centered.  
   - $\sigma$ says **how wide** it spreads.

3. **Estimation from Data**  
   Simple **averages** give you a decent first guess at $\mu$ and $\sigma^2$.

4. **Foundation for Anomaly Detection**  
   Use the Gaussian model to see which points are **common** vs. **rare**.  
   Rare points may indicate **problems** or **interesting outliers**.

Understanding **Gaussian distributions** equips you with a **powerful** tool, not only in **anomaly detection** but in countless other areas (testing hypotheses, analyzing measurement errors, financial modeling and risk assessment, or just figuring out how random things distribute!). It's one of the **cornerstones** of statistics and machine learning.

---

## ***Anomaly Detection Algorithm***

### ***Have you ever wondered how to detect anomalies when you have multiple features at once?***

Previously, we looked at how a single-feature Gaussian (Normal) distribution can help us identify unusual data points. But in **real-world** scenarios, we often have **more than one** feature—like temperature, vibration, and pressure all at once. How do we extend the idea of a **bell curve** into multiple dimensions? That’s where **density estimation** with multiple features comes in.

---

### ***1. Modeling Multiple Features***

Let’s say each example $\vec{x}^{(i)}$ has **$n$ features**:

$$
\vec{x}^{(i)} =
\begin{pmatrix}
x_1^{(i)} \\
x_2^{(i)} \\
\vdots \\
x_n^{(i)}
\end{pmatrix}.
$$

For anomaly detection, we want to model the **probability** of observing each feature combination:
$$
p(\vec{x}) = p(x_1, x_2, \dots, x_n).
$$

**Assumption** (for simplicity):  
We often assume the features are **independently** distributed (although this can be an approximation). In that case,

$$
p(\vec{x}) = p(x_1)\,p(x_2)\,\cdots\,p(x_n).
$$

Then we can **fit** each feature with its own 1D Gaussian, characterized by $(\mu_j, \sigma_j^2)$ for $j = 1, 2, \dots, n.$

> **Analogy**: Think of each feature as a separate **bell curve**. The combined probability is like **multiplying** these bell-curve probabilities together, giving a single measure of how “normal” your entire set of features is at once.

---

### ***2. Fitting the Gaussian Parameters***

For each feature $j$, we estimate its:
- **Mean**:  
  $$
  \mu_j = \frac{1}{m} \sum_{i=1}^{m} x_j^{(i)}.
  $$
- **Variance**:  
  $$
  \sigma_j^2 = \frac{1}{m} \sum_{i=1}^{m} \bigl(x_j^{(i)} - \mu_j\bigr)^2.
  $$

Here,
- $x_j^{(i)}$ is the value of feature $j$ in the $i$ th example,
- $m$ is the number of training examples (all assumed “normal” data).

Once we have **$\mu_j$** and **$\sigma_j^2$** for **each** feature $j$, we can write the probability density for the entire feature vector $\vec{x}$:  

$$
p(\vec{x}) = \prod_{j=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x - \mu)^2}{2\sigma^2}}
$$

---

### ***3. Computing the Anomaly Score***

1. **Calculate $p(\vec{x}^{\text{test}})$**  
   - Plug your new test point’s features into the formula for $p(\vec{x})$.  
   - If the result (probability) is **very small**, it indicates $\vec{x}^{\text{test}}$ is **unlikely** under the model of “normal” data.

2. **Threshold $\varepsilon$ (epsilon)**  
   - Choose a **small** cutoff $\varepsilon$.  
   - If $p(\vec{x}^{\text{test}}) < \varepsilon$, **flag** it as an anomaly.

> **Why a threshold?**  
> Because you need a **practical** way to say: “When is a probability *so small* that we consider it suspicious?”

---

### ***4. Putting It All Together: Steps of the Algorithm***

1. **Choose $n$ Features**  
   - Pick features you believe might show **anomalous** behavior if something goes wrong (e.g., temperature, vibration, memory usage, etc.).

2. **Estimate Parameters**  
   - For each feature $j$:  

$$
\mu_j = \frac{1}{m} \sum_{i=1}^{m} x_j^{(i)}, 
\quad
\sigma_j^2 = \frac{1}{m} \sum_{i=1}^{m} (x_j^{(i)} - \mu_j)^2.
$$

3. **Compute Probability for a New Example**  
   - For a new $\vec{x}^{\text{test}}$, calculate:  

$$
p(\vec{x}^{\text{test}}) = \prod_{j=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x - \mu)^2}{2\sigma^2}}
$$

4. **Compare with Threshold $\varepsilon$**  
   - If $p(\vec{x}^{\text{test}}) < \varepsilon$, **label** it as **anomaly**; otherwise, it’s considered **normal**.

---

### ***5. Why This Works***

- **Captures Each Feature’s Behavior**  
  By modeling each feature’s distribution separately, you account for what’s “normal” for that specific attribute (e.g., typical engine temperature range).
- **Combines Them Together**  
  The **product** of probabilities ensures that a **very low** probability on **any** key feature can make the overall probability small—hinting that something’s amiss.
- **Threshold Tuning**  
  Adjusting $\varepsilon$ helps control the **trade-off** between catching real anomalies (true positives) and avoiding too many **false alarms**.

---

### ***6. Key Takeaways***

1. **Multiple Features, One Probability**  
   - We treat each feature with a **Gaussian** and multiply them to get the final $p(\vec{x})$.
2. **Simple Parameter Estimation**  
   - Just compute the **mean** and **variance** for each feature from your (normal) training data.
3. **Flexible & Extendable**  
   - Add or remove features depending on your problem. The approach remains the same.
4. **Threshold for Anomalies**  
   - Decide a **cutoff** that flags data points with extremely **low** probability as “suspicious.”

Whether you’re dealing with **aircraft engines**, **web server logs**, or **credit card transactions**, this multi-feature Gaussian approach is a straightforward and effective way to spot things that just **don’t** look like they belong. It’s the core principle behind many industrial-scale anomaly detection systems, quietly ensuring **safety** and **security** across countless applications.