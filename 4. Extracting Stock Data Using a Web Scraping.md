# Extracting Stock Data Using a Web Scraping
## 1) Scenario
I am working for a new startup investment firm that helps customers invest their money in stocks.  
My job is to extract financial data like historical share price and quarterly revenue reportings from various sources using Python libraries and webscraping on popular stocks.  
After collecting this data I will visualize it in a dashboard to identify patterns or trends. The stocks I will work with are ***Apple, NVIDIA***.

## 2) Setup

```python
!pip install pandas
!pip install requests
!mamba install bs4
!pip install lxml
!pip install plotly
```
```python
import pandas as pd              # Importing the pandas library for data manipulation
import requests
import os                        # Importing the os library for operating system interactions
import json                      # Importing the json library for JSON file handling
from bs4 import Beautifulsoup
```

## 3) Steps
I will extract Nvidia stock data https://finance.yahoo.com/quote/NVDA/history/?frequency=1mo&period1=1533772800&period2=1717891200   

I am using yahoo finance website and looking to extract Nvidia data.  

![table1](https://github.com/Atikers/Images/blob/main/Project%20%234%20-%20image(1).jpg)  

### (1) Step 1 : Sending an HTTP request to the web page
I will use the request library for sending an HTTP request to the web page.  
```python
url="https://finance.yahoo.com/quote/NVDA/history/?frequency=1mo&period1=1533772800&period2=1717891200"
```
The `requests.get()` method takes a URL as its first argument, which specifies the location of the resource to be retrieved.  
In this project, the value of the url variable is passed as the argument to the `requests.get()` method,  
because I will store a web page URL in a url variable.  

I use the `.text` method for extracting the HTML content as a string in order to make it readable.  
```python
data=requests.get(url).text
print(data)
```

### (2) Step 2 : Parsing the HTML content

Parsing the data using the BeautifulSoup library
```python
soup=BeautifulSoup(data, 'html.parser')
```

### (3) Step 3 : Identifying the HTML tags

```python
nvidia_data=pd.DataFrame(columns=["Date", "Open", "High", "Low", "Close", "Volume"])
```
>**Working on HTML table**    
>**&lt;table&gt;** : This tag is a root tag used to define the start and end of the table. All the content of the table is enclosed within these tags.    
>**&lt;tr&gt;** : This tag is used to define a table **row**. Each row of the table is defined within this tag.    
>**&lt;td&gt;** : This tag is used to define a table **cell**. Each cell of the table is defined within this tag. You can specify the content of the cell between the opening and closing tags.    
>**&lt;th&gt;** : This tag is used to define a header cell in the table. The header cell is used to describe the contents of a column or row. By default, the text inside a tag is bold and centered.    
>**&lt;tbody&gt;** : This is the main content of the table, which is defined using the tag. It contains one or more rows of elements.    

### (4) Step 4 : Using a BeautifulSoup method for extracting data
I will use `find()` and `find_all()` methods of the BeautifulSoup object to locate the table body and table row respectively in the HTML.
* The `find()` method will return particular tag content.
* The `find_all()` method returns a list of all matching tags in the HTML.
```python
for row in soup.find("tbody").find_all('tr'):
    col = row.find_all("td")
    date = col[0].text
    Open = col[1].text
    high = col[2].text
    low = col[3].text
    close = col[4].text
    adj_close = col[5].text
    volume = col[6].text
    nvidia_data = pd.concat([nvidia_data,pd.DataFrame({"Date":[date], "Open":[Open], "High":[high], "Low":[low], "Close":[close], "Adj Close":[adj_close], "Volume":[volume]})], ignore_index=True)
```
### (5) Step 5 : Printing the extracted data
```python
nvidia_data.head()
```
