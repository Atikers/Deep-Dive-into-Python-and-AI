# Analyzing Stock Performance and Building a Dashboard, Visualizing using a Web Scraping
## 1) Scenario
This time, I will use web scraping to gather financial data, analyze stock performance, and build a dashboard.    
The focus will be on collecting historical share prices and revenue data for ***Microsoft***.    
By leveraging Python's web scraping libraries, I aim to visualize this data interactively to identify trends and provide insights for investment strategies.

## 2) Setup
```python
!pip install yfinance
!pip install pandas            # For data manipulation and analysis
!pip install requests          # For making HTTP requests to fetch web pages
!pip install nbformat          # For Jupyter Notebook file handling (if needed)
!pip install bs4               # For parsing HTML and XML documents
!pip install lxml              # For parsing XML and HTML (used by BeautifulSoup)
!pip install plotly            # For interactive data visualization
!pip install selenium          # For web scraping, especially for dynamically loaded content
!pip install webdriver-manager
```
```python
import os                # Importing the os library for operating system interactions
import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup
import lxml
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time
import json      # Importing the json library for JSON file handling
```
```python
# Setting up Selenium WebDriver
service = Service(ChromeDriverManager().install())
options = webdriver.ChromeOptions()
options.add_argument("--headless")  # Run in headless mode
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(service=service, options=options)
```
In this project, I define the function `make_graph`. It takes a dataframe with **stock data** (**Date** and **Close** columns), a dataframe with **revenue data** (**Date** and **Revenue** columns), and the name of the stock.
```python
def make_graph(stock_data, revenue_data, stock):
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, subplot_titles=("Historical Share Price", "Historical Revenue"), vertical_spacing = .3)

    # Converting the 'Date' columns to datetime
    stock_data['Date'] = pd.to_datetime(stock_data['Date'])
    revenue_data['Date'] = pd.to_datetime(revenue_data['Date'])
    
    # Filtering data up to the specified dates
    stock_data_specific = stock_data[stock_data['Date'] <= '2024-03-31']
    revenue_data_specific = revenue_data[revenue_data['Date'] <= '2024-03-31']
    
    # Adding traces for stock prices and revenue
    fig.add_trace(go.Scatter(x=stock_data_specific['Date'], y=stock_data_specific['Close'].astype("float"), name="Share Price"), row=1, col=1)
    fig.add_trace(go.Scatter(x=revenue_data_specific['Date'], y=revenue_data_specific['Revenue'].astype("float"), name="Revenue"), row=2, col=1)
    
    # Updating x-axes and y-axes titles
    fig.update_xaxes(title_text="Date", row=1, col=1)
    fig.update_xaxes(title_text="Date", row=2, col=1)
    fig.update_yaxes(title_text="Price ($US)", row=1, col=1)
    fig.update_yaxes(title_text="Revenue ($US Millions)", row=2, col=1)
    
    # Updating layout
    fig.update_layout(showlegend=True,
                      height=900,
                      title=stock,
                      xaxis_rangeslider_visible=True)
    
    # Showing the figure
    fig.show()
```

## 3) Steps
### (1) Step 1 : Using yfinance to Extract Stock Data    
```python
# Using yfinance to Extract Stock Data
Microsoft = yf.Ticker("MSFT")

# Extracting stock information and save it in a dataframe named Microsoft_data   
Microsoft_data = Microsoft.history(period="max")

# Resetting the index
Microsoft_data.reset_index(inplace=True)
print(Microsoft_data.head())
```
Then, I get the following :    
![image1]()


### (2) Step 2 : Using Webscraping to Extract Microsoft Revenue Data
```python
# Fetch the web page
url = "https://www.macrotrends.net/stocks/charts/MSFT/microsoft/revenue"
driver.get(url)

# Waiting for the page to fully load
time.sleep(5)

# Extracting page source and parse with BeautifulSoup
html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

# Closing the WebDriver
driver.quit()

# Saving the HTML content to a file
current_directory = os.getcwd()
file_path = os.path.join(current_directory, "saved_page.html")
with open(file_path, 'w', encoding='utf-8') as file:
    file.write(str(soup))

# Reading the saved HTML file
with open(file_path, 'r', encoding='utf-8') as file:
    html_content = file.read()

# Parsing the HTML using BeautifulSoup
soup = BeautifulSoup(html_content, 'html.parser')

# Finding the table containing the financial data
table = soup.find('table', {'class': 'historical_data_table'})

# Initializing a list to store revenue data
data = []

# Looping through each row in the table
for row in table.find_all('tr')[1:]:  # Skip the header row
    cols = row.find_all('td')
    if len(cols) > 1:
        date = cols[0].text.strip()
        revenue = cols[1].text.strip().replace('$', '').replace(',', '')
        data.append([date, revenue])

# Converting the data into a pandas DataFrame
columns = ['Date', 'Revenue']
Microsoft_revenue = pd.DataFrame(data, columns=columns)

# Converting 'Date' column to datetime format
Microsoft_revenue['Date'] = pd.to_datetime(Microsoft_revenue['Date'])

# Converting 'Revenue' column to float
Microsoft_revenue['Revenue'] = Microsoft_revenue['Revenue'].astype(float)

# Printing the DataFrame to verify the data
print(Microsoft_revenue.head())
```


### (3) Step 3 : Plotting Microsoft Stock Graph
To graph the Microsoft Stock Data, Using the `make_graph` function(Graph will only show data upto March 2024).

```python
make_graph(Microsoft_data, Microsoft_revenue, 'Microsoft')
```
Then, I get the following :
![image2](https://github.com/Atikers/Images/blob/main/Project%20%234%20-%20image(2).jpg)

