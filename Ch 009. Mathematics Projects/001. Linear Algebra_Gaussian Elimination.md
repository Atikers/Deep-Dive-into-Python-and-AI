# **Gaussian Elimination**

Gaussian elimination is a classical and foundational algorithm for solving systems of linear equations. While there are more advanced methods today, understanding Gaussian elimination provides invaluable insights into the core principles of linear algebra—principles that are widely applied in machine learning, data science, engineering, and more.

## **1. Why Gaussian Elimination Matters**

1. **Fundamental Skills**  
   You will strengthen your grasp on the basic operations (row swaps, scaling, and elimination) that lie at the heart of linear algebra.
2. **Clear and Systematic**  
   The algorithm offers a logical, step-by-step “recipe” for transforming your system of equations into a form where solutions are easy to read off.
3. **Springboard to Advanced Topics**  
   Mastery of Gaussian elimination serves as a gateway to more sophisticated methods (e.g., LU decomposition, Gauss-Jordan elimination, iterative solvers in high-performance computing, etc.).

## **2. Concepts Overview**

### **2.1 Augmented Matrix**

Given a system of linear equations:  

$$
\begin{cases}
2x_1 + 3x_2 + 5x_3 = 12 \\
-3x_1 - 2x_2 + 4x_3 = -2 \\
x_1 + x_2 - 2x_3 = 8
\end{cases}
$$

we separate the **coefficient matrix** (the left-hand side) from the **constant terms** (the right-hand side) but keep them together in what’s called an **augmented matrix**:  

$$
\bigl[A \mid B\bigr] =
\begin{pmatrix}
2 & 3 & 5 & \Big| & 12 \\
-3 & -2 & 4 & \Big| & -2 \\
1 & 1 & -2 & \Big| & 8
\end{pmatrix}
$$

This augmented matrix keeps all the information about the system in one place.

### **2.2 Row Echelon Form**

To solve the system systematically, we aim to convert the augmented matrix into a **row echelon form** (REF). In this form:

1. Any rows of all zeros appear at the bottom.
2. Each non-zero row has a leftmost non-zero entry (pivot) that is to the right of the pivot above it.
3. All entries below each pivot are zero.

**Example** of a $3\times3$ matrix in REF (ignoring constants on the right for simplicity) might look like:  

$$
\begin{pmatrix}
a & b & c \\
0 & d & e \\
0 & 0 & f
\end{pmatrix}
$$

where each pivot $a$, $d$, $f$ is non-zero.

### **2.3 Back Substitution and Reduced Row Echelon Form**

After achieving REF, you can solve for variables from the bottom row upward (back substitution). Alternatively, you can continue to **eliminate the entries above each pivot** to reach the **reduced row echelon form** (RREF), in which every pivot becomes 1, and every other entry in each pivot’s column is 0. At that stage, the solution can often be read directly from the matrix.

### **2.4 Algorithm at a Glance**

1. **Form the Augmented Matrix**: Combine the coefficient matrix $A$ with the constant column $B$.
2. **Forward Elimination**:  
   - Pivot on the main diagonal (one pivot in each row, from top to bottom).  
   - Swap rows if the pivot is zero to bring a non-zero pivot up.  
   - Scale each pivot to 1.  
   - Eliminate the entries below each pivot to form zeros in its column.
3. **Back Substitution** or **Further Elimination**:  
   - Either solve from the bottom row up or continue to reduce above the pivots.  
   - If the matrix is **singular**, you may discover a row of zeros that either indicates infinitely many solutions (if the constant is also zero) or no solution (if the constant is non-zero).

## **3. Step-by-Step Implementation in Python**

Below is a simple Python-based outline showing how you might code Gaussian elimination from scratch. The examples assume non-singular systems for brevity.

> **Note**: The following code snippets show a generic approach. Adjust function names or structures as you like.

### **3.1 Swapping Rows**

```python
import numpy as np

def swap_rows(M, row_index_1, row_index_2):
    """
    Returns a new matrix where two rows of M are swapped.
    """
    M = M.copy()
    M[[row_index_1, row_index_2]] = M[[row_index_2, row_index_1]]
    return M
```

### **3.2 Building the Augmented Matrix**

```python
def augmented_matrix(A, B):
    """
    Create an augmented matrix by horizontally stacking A and B.
    A: n x n coefficient matrix
    B: n x 1 column of constants
    """
    return np.hstack((A, B))
```

### **3.3 Finding the First Non-Zero Entry**

Sometimes a pivot candidate is zero, so we look below it for a suitable row to swap. Here’s a helper to find a non-zero entry in a given column, starting from a specified row:

```python
def get_index_first_non_zero_value_from_column(M, column, starting_row):
    """
    Return the index of the first non-zero value in 'column', 
    searching from 'starting_row' to the bottom. 
    Returns -1 if none is found.
    """
    col_slice = M[starting_row:, column]
    for i, val in enumerate(col_slice):
        if not np.isclose(val, 0, atol=1e-5):
            return i + starting_row
    return -1
```

### **3.4 Row Echelon Form Function**

```python
def row_echelon_form(A, B):
    """
    Transform the system (A|B) into row echelon form.
    Assumes A is non-singular (unique solution).
    """
    # Check determinant to confirm non-singularity
    if np.isclose(np.linalg.det(A), 0):
        return "Singular system"
    
    A = A.astype(float)
    B = B.astype(float)
    M = augmented_matrix(A, B)
    n = len(A)  # number of rows/columns for a square matrix

    for row in range(n):
        pivot_candidate = M[row, row]

        # If pivot is zero, search for a non-zero entry below it.
        if np.isclose(pivot_candidate, 0, atol=1e-5):
            swap_index = get_index_first_non_zero_value_from_column(M, row, row)
            if swap_index == -1:
                return "Singular system"
            M = swap_rows(M, row, swap_index)
            pivot_candidate = M[row, row]
        
        # Scale row to make pivot = 1
        M[row] /= pivot_candidate

        # Eliminate entries below pivot
        for below in range(row + 1, n):
            factor = M[below, row]
            M[below] -= factor * M[row]

    return M
```

### **3.5 Back Substitution**

After obtaining row echelon form, you can “go back upward” to get zeros above each pivot. This yields the fully solved system (or the **reduced** row echelon form if you zero out all above-pivot entries).

```python
def back_substitution(M):
    """
    Given an n x (n+1) augmented matrix in row echelon form with unit pivots,
    perform the final elimination steps from bottom to top.
    Returns the solution vector.
    """
    M = M.copy()
    n = M.shape[0]

    # From last row upward
    for row in reversed(range(n)):
        # The pivot is on the diagonal => (row, row)
        # Zero out above entries in the pivot’s column
        for above in range(row):
            factor = M[above, row]
            M[above] -= factor * M[row]

    # The solution is simply the last column
    return M[:, -1]
```

### **3.6 Putting It All Together**

```python
def gaussian_elimination(A, B):
    """
    Solve A x = B for x using Gaussian Elimination and Back Substitution.
    Assumes A is square and non-singular, so a unique solution exists.
    """
    # Convert to row echelon form
    ref_matrix = row_echelon_form(A, B)
    if isinstance(ref_matrix, str):
        # If the function returns a string, it indicates a singular system
        return ref_matrix  # "Singular system"

    # Now perform back-substitution
    solution = back_substitution(ref_matrix)
    return solution
```

## **4. Handling Special Cases**

1. **Singular System (No or Infinite Solutions)**  
   - If you detect a full zero row in the coefficient part but a non-zero entry in the constant column, there is no solution.  
   - If you detect a full zero row in both the coefficient and constant columns, you have infinitely many solutions.

2. **Practical Numerical Issues**  
   - Real computations can introduce floating-point round-off errors. Functions like `np.isclose` help mitigate direct equality checks with zero.

## **5. Example Usage**

Below is a short demonstration. Suppose we have the system:  

$$
\begin{cases}
3a + 6b = 12 \\
5a + 3b = -10
\end{cases}
$$

We can write:

```python
import numpy as np

A = np.array([
    [3, 6],
    [5, 3]
])
B = np.array([
    [12],
    [-10]
])

solution = gaussian_elimination(A, B)
print(solution)
```

If non-singular, the output will be the vector $[a,b]$—your unique solution.

## **6. Final Thoughts**

- **Gaussian Elimination** is both simple and powerful.  
- It underpins more advanced linear algebra methods.  
- Learning to implement it by hand (or in code) gives you deep insight into how solutions to linear systems are systematically found.

This project highlights each step: from forming the augmented matrix, creating row echelon form, and performing back substitution. By following these steps carefully, you can handle a wide range of linear systems with confidence.